{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0                                               text  label\n",
      "1  We should keep the Electoral College for a num...      0\n",
      "2  More and more money is spent on building theat...      1\n",
      "3  Limiting car usage can actually be effective b...      0\n",
      "4  Dear Mrs. Smith,\\r\\n\\r\\nI am writing to you to...      1\n",
      "5  Dear Principal,\\r\\n\\r\\nAfter school or during ...      0\n",
      "6  Many people think that aliens are real, but th...      0\n",
      "7  Our parents used to tell us not to stick to on...      1\n",
      "8  When it comes to technology, some people would...      1\n",
      "9  I think if a student has a C average he or she...      0\n"
     ]
    }
   ],
   "source": [
    "# Replace 'your_file_path.csv' with the actual path to your CSV file\n",
    "train_file_path = 'final_train.csv'\n",
    "test_file_path = 'final_test.csv'\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "train_df = pd.read_csv(train_file_path, header=None, names=['text', 'label'])\n",
    "test_df = pd.read_csv(test_file_path, header=None, names=['text', 'label'])\n",
    "\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(train_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_df['text']\n",
    "train_label = train_df['label']\n",
    "\n",
    "test_text = test_df['text']\n",
    "test_label = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\STA Laptop\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50000\n",
    "\n",
    "Tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
    "Tokenizer.fit_on_texts(train_text)\n",
    "\n",
    "word_index = Tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokenizer to JSON string\n",
    "tokenizer_json = Tokenizer.to_json()\n",
    "\n",
    "# Save the tokenizer to a file\n",
    "with open('tokenizer.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(tokenizer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame containing the 'text' column\n",
    "sequence_lengths = train_df['text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Plot a histogram of sequence lengths\n",
    "plt.hist(sequence_lengths, bins=150)\n",
    "plt.title('Distribution of Sequence Lengths')\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokenizer.fit_on_sequences(train_text)\n",
    "train_sequences = Tokenizer.texts_to_sequences(train_text)\n",
    "padded = pad_sequences(train_sequences, maxlen=1000, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokenizer.fit_on_sequences(test_text)\n",
    "test_sequences = Tokenizer.texts_to_sequences(test_text)\n",
    "testing_padded = pad_sequences(test_sequences, maxlen=1000, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 200\n",
    "max_length = 1000\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_label = [str(label) for label in train_label]\n",
    "test_label = [str(label) for label in test_label]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "train_label = encoder.fit_transform(train_label)\n",
    "test_label = encoder.transform(test_label)\n",
    "\n",
    "train_label = np.array(train_label).astype('float32')\n",
    "test_label = np.array(test_label).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(padded, train_label, epochs=30, validation_data=(testing_padded, test_label), verbose=1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m Tokenizer(num_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# replace train_data with your actual training data\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mfit_on_texts(\u001b[43mtrain_text\u001b[49m)\n\u001b[0;32m      9\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRespected sir, this is very heartly and peaceful message that \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mI want to convey to you regarding my outstanding fees. I am a student of your school and I\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m am in class 10th. I have been studying in your school for\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m the last 5 years. I have always been a good student of \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124myours\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis snippet ensures that TensorFlow \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mdynamically allocates GPU memory as needed, preventing it \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mfrom occupying the entire GPU memory at once.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn Pakistan, the government is not doing anything to change the current situation of the country. The government is corrupt and is not doing anything to change the current situation of the country. The government is corrupt and is not doing anything to change the current situation of the country. The government is corrupt and is not doing anything to change the current situation of the country. The government is corrupt and is not doing anything to change the current situation of the country. The government is corrupt and is not doing anything to change the current situation of the country. The government is corrupt and is not doing anything to change the current situation of the country. The government is corrupt and is not doing anything to change the current situation of the country. The government is corrupt and is not doing anything to change the current situation of the country. But still, we are hopeful that things will change in the future.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     17\u001b[0m ]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Convert texts to sequences\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_text' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Create a tokenizer and fit it on your training data\n",
    "# replace num_words with the actual number used in your model\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "# replace train_data with your actual training data\n",
    "tokenizer.fit_on_texts(train_text)\n",
    "\n",
    "sentences = [\n",
    "    'Respected sir, this is very heartly and peaceful message that \\nI want to convey to you regarding my outstanding fees. I am a student of your school and I\\n am in class 10th. I have been studying in your school for\\n the last 5 years. I have always been a good student of \\nyours',\n",
    "    'This snippet ensures that TensorFlow \\ndynamically allocates GPU memory as needed, preventing it \\nfrom occupying the entire GPU memory at once.',\n",
    "    'The more you eat sumeed the more ubaid you''ll get',\n",
    "    'The american army recently invaded iraq and killed many innocent people have also stepped foot to manufacture drugs that might harm innocent people of Palestine.',\n",
    "    'Our data is not AI generated instead it is human written. BELIEVE ME!',\n",
    "    'The more you eat the more you''ll get',\n",
    "    'In Pakistan, the government is not doing anything to change the current situation of the country. The government is corrupt and is not doing anything to change the current situation of the country. The government is corrupt and is not doing anything to change the current situation of the country. The government is corrupt and is not doing anything to change the current situation of the country. The government is corrupt and is not doing anything to change the current situation of the country. The government is corrupt and is not doing anything to change the current situation of the country. The government is corrupt and is not doing anything to change the current situation of the country. The government is corrupt and is not doing anything to change the current situation of the country. The government is corrupt and is not doing anything to change the current situation of the country. But still, we are hopeful that things will change in the future.'\n",
    "]\n",
    "\n",
    "# Convert texts to sequences\n",
    "sample_sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "padding_type = 'post'\n",
    "# replace max_length with the actual length used in your model\n",
    "sample_padded = pad_sequences(\n",
    "    sample_sequences, padding=padding_type, maxlen=max_length)\n",
    "\n",
    "# Predicting\n",
    "classes = model.predict(sample_padded)\n",
    "\n",
    "i = 0\n",
    "for value in classes:\n",
    "    if value > 0.5:\n",
    "        print(\"\\n\\nText \", sentences[i])\n",
    "        print(\"\\nAI Generated :Positive with value of \", value)\n",
    "    else:\n",
    "        print(\"\\n\\nText \", sentences[i])\n",
    "        print(\"\\nHuman Written: Negative with value of \", value)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
